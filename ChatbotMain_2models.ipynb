{
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RyLz__zlVyBR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bU_Wxn3iVsT1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyJBh459vVSt",
        "outputId": "8416007b-2564-440c-a8a1-6a77030092e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "Tensorflow version 2.15.0\n"
          ]
        }
      ],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import sys\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "  %tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.random.set_seed(1234)\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "#import tensorflow_datasets as tfds\n",
        "\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "from time import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "import time\n",
        "\n",
        "print(\"Tensorflow version {}\".format(tf.__version__))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZVvWyJF0CWrB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec46a856-1c02-44d9-b340-d75beb519032"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuoMHALUaA4E"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Uzj5Ybu8aCiT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OlbvSqhuV9YT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6rUDArI2wDFQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84a01342-32c3-4b72-e2ad-cde4bae9b085"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "REPLICAS: 1\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Running on TPU {}'.format(tpu.cluster_spec().as_dict()['worker']))\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "else:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "print(\"REPLICAS: {}\".format(strategy.num_replicas_in_sync))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "P9lm2mHgwJ4w"
      },
      "outputs": [],
      "source": [
        "# Maximum sentence length\n",
        "MAX_LENGTH = 40\n",
        "\n",
        "# Maximum number of samples to preprocess\n",
        "MAX_SAMPLES = 2000\n",
        "\n",
        "# For tf.data.Dataset\n",
        "BATCH_SIZE = 64 * strategy.num_replicas_in_sync\n",
        "BUFFER_SIZE = 20000\n",
        "\n",
        "# For Transformer\n",
        "NUM_LAYERS = 2\n",
        "D_MODEL = 256\n",
        "NUM_HEADS = 8\n",
        "UNITS = 512\n",
        "DROPOUT = 0.1\n",
        "\n",
        "EPOCHS = 120"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "hfotN5CKwP63"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "M7ZBaATNwznG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/sample_data/BengaliEmpatheticConversationsCorpus .csv\", encoding='utf-8')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yrKtxx54xBTH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "c24d6f5c-bf33-4413-ecfe-dc627073799b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             Topics  \\\n",
              "0                পারিবারিক দ্বন্দ্ব   \n",
              "1        পদার্থের অপব্যবহার, আসক্তি   \n",
              "2                পারিবারিক দ্বন্দ্ব   \n",
              "3  আচরণগত পরিবর্তন, সামাজিক সম্পর্ক   \n",
              "4                        দুশ্চিন্তা   \n",
              "\n",
              "                                   Question-Title  \\\n",
              "0              মা ও স্ত্রীর মধ্যে মতানৈক্য বৃদ্ধি   \n",
              "1      আমি ধূমপানে আসক্ত। আমি কিভাবে থামাতে পারি?   \n",
              "2                আমার পরিবারের কাছ থেকে গোপন রাখা   \n",
              "3                 অধিকারী হওয়ার অন্তর্নিহিত কারণ   \n",
              "4  আমি কি ওষুধ ছাড়া উদ্বেগ নিয়ন্ত্রণ করতে পারি?   \n",
              "\n",
              "                                           Questions  \\\n",
              "0   আমার স্ত্রী এবং মায়ের মধ্যে টানটান মতবিরোধ চ...   \n",
              "1   আমি বাচ্চা নেওয়ার পরিকল্পনা করছি, তাই আমাকে ...   \n",
              "2   আমার মনের মধ্যে গোপন আছে, এবং আমি জানি না তাদ...   \n",
              "3  আমি আমার সম্পর্কের ক্ষেত্রে অত্যন্ত অধিকারসূচক...   \n",
              "4  কয়েক বছর আগে আমার মাথায় আঘাত লেগেছিল এবং আমা...   \n",
              "\n",
              "                                             Answers  \n",
              "0   আপনি যা বর্ণনা করছেন তাকে মনোবিজ্ঞানীরা \"ত্রি...  \n",
              "1   হাই। আপনার শিশুর (এবং নিজের) জন্য যা স্বাস্থ্...  \n",
              "2   মনে হচ্ছে গোপন রাখা এখন আপনার জন্য একটি সমস্য...  \n",
              "3   হ্যালো। এটা দুর্দান্ত যে আপনি উপলব্ধি করতে সক...  \n",
              "4   আপনি বলেননি কি বা কত ওষুধ আপনি চেষ্টা করেছেন।...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c6734025-4c95-4c46-a3b7-d6f13d03a34a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topics</th>\n",
              "      <th>Question-Title</th>\n",
              "      <th>Questions</th>\n",
              "      <th>Answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>পারিবারিক দ্বন্দ্ব</td>\n",
              "      <td>মা ও স্ত্রীর মধ্যে মতানৈক্য বৃদ্ধি</td>\n",
              "      <td>আমার স্ত্রী এবং মায়ের মধ্যে টানটান মতবিরোধ চ...</td>\n",
              "      <td>আপনি যা বর্ণনা করছেন তাকে মনোবিজ্ঞানীরা \"ত্রি...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>পদার্থের অপব্যবহার, আসক্তি</td>\n",
              "      <td>আমি ধূমপানে আসক্ত। আমি কিভাবে থামাতে পারি?</td>\n",
              "      <td>আমি বাচ্চা নেওয়ার পরিকল্পনা করছি, তাই আমাকে ...</td>\n",
              "      <td>হাই। আপনার শিশুর (এবং নিজের) জন্য যা স্বাস্থ্...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>পারিবারিক দ্বন্দ্ব</td>\n",
              "      <td>আমার পরিবারের কাছ থেকে গোপন রাখা</td>\n",
              "      <td>আমার মনের মধ্যে গোপন আছে, এবং আমি জানি না তাদ...</td>\n",
              "      <td>মনে হচ্ছে গোপন রাখা এখন আপনার জন্য একটি সমস্য...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>আচরণগত পরিবর্তন, সামাজিক সম্পর্ক</td>\n",
              "      <td>অধিকারী হওয়ার অন্তর্নিহিত কারণ</td>\n",
              "      <td>আমি আমার সম্পর্কের ক্ষেত্রে অত্যন্ত অধিকারসূচক...</td>\n",
              "      <td>হ্যালো। এটা দুর্দান্ত যে আপনি উপলব্ধি করতে সক...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>দুশ্চিন্তা</td>\n",
              "      <td>আমি কি ওষুধ ছাড়া উদ্বেগ নিয়ন্ত্রণ করতে পারি?</td>\n",
              "      <td>কয়েক বছর আগে আমার মাথায় আঘাত লেগেছিল এবং আমা...</td>\n",
              "      <td>আপনি বলেননি কি বা কত ওষুধ আপনি চেষ্টা করেছেন।...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6734025-4c95-4c46-a3b7-d6f13d03a34a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c6734025-4c95-4c46-a3b7-d6f13d03a34a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c6734025-4c95-4c46-a3b7-d6f13d03a34a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-45cebc37-be23-417d-af4e-c62956b4c68c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-45cebc37-be23-417d-af4e-c62956b4c68c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-45cebc37-be23-417d-af4e-c62956b4c68c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "X1--_NVpxHOo"
      },
      "outputs": [],
      "source": [
        "df=df.drop([\"Topics\",\"Question-Title\"],axis=1)\n",
        "df.rename(columns={'Questions': 'Question', 'Answers': 'Answer'}, inplace=True)\n",
        "# df = df.iloc[:15000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2Nag_3hoxJxx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "b8e10489-3606-443b-e29c-82bc19a2a8e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Question  \\\n",
              "0      আমার স্ত্রী এবং মায়ের মধ্যে টানটান মতবিরোধ চ...   \n",
              "1      আমি বাচ্চা নেওয়ার পরিকল্পনা করছি, তাই আমাকে ...   \n",
              "2      আমার মনের মধ্যে গোপন আছে, এবং আমি জানি না তাদ...   \n",
              "3     আমি আমার সম্পর্কের ক্ষেত্রে অত্যন্ত অধিকারসূচক...   \n",
              "4     কয়েক বছর আগে আমার মাথায় আঘাত লেগেছিল এবং আমা...   \n",
              "...                                                 ...   \n",
              "5486                                   হ্যাঁ এটা সত্যিই   \n",
              "5487  আমি কাজ শেষে আজ রেজিস্ট্রেশন সেন্টারে গিয়েছিল...   \n",
              "5488  আমি কিছু বন্ধুদের সাথে ভলিবল খেলি। কাজের পরে আ...   \n",
              "5489  আমি খুব রাগান্বিত হয়েছিলাম যখন আমার মা..যিনি ...   \n",
              "5490  তিনি তাদের পিছন পিছন মানুষের সম্পর্কে খারাপ কথ...   \n",
              "\n",
              "                                                 Answer  \n",
              "0      আপনি যা বর্ণনা করছেন তাকে মনোবিজ্ঞানীরা \"ত্রি...  \n",
              "1      হাই। আপনার শিশুর (এবং নিজের) জন্য যা স্বাস্থ্...  \n",
              "2      মনে হচ্ছে গোপন রাখা এখন আপনার জন্য একটি সমস্য...  \n",
              "3      হ্যালো। এটা দুর্দান্ত যে আপনি উপলব্ধি করতে সক...  \n",
              "4      আপনি বলেননি কি বা কত ওষুধ আপনি চেষ্টা করেছেন।...  \n",
              "...                                                 ...  \n",
              "5486  এটি একটি অবিচলিত গতিতে অর্জন করা হচ্ছে... এটি ...  \n",
              "5487                   এটাই সমস্যা। তুমি সেখানে কি করছ?  \n",
              "5488  চমৎকার আহ! তোমার জন্য ভালো. সম্ভবত একটি রান জন...  \n",
              "5489     কি দারুন. তোর মাকে নিয়ে তোর খালা কি রেগে আছে?  \n",
              "5490                                                NaN  \n",
              "\n",
              "[5491 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b8ad8f3-eb9a-42ec-9af9-6df6074c3396\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>আমার স্ত্রী এবং মায়ের মধ্যে টানটান মতবিরোধ চ...</td>\n",
              "      <td>আপনি যা বর্ণনা করছেন তাকে মনোবিজ্ঞানীরা \"ত্রি...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>আমি বাচ্চা নেওয়ার পরিকল্পনা করছি, তাই আমাকে ...</td>\n",
              "      <td>হাই। আপনার শিশুর (এবং নিজের) জন্য যা স্বাস্থ্...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>আমার মনের মধ্যে গোপন আছে, এবং আমি জানি না তাদ...</td>\n",
              "      <td>মনে হচ্ছে গোপন রাখা এখন আপনার জন্য একটি সমস্য...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>আমি আমার সম্পর্কের ক্ষেত্রে অত্যন্ত অধিকারসূচক...</td>\n",
              "      <td>হ্যালো। এটা দুর্দান্ত যে আপনি উপলব্ধি করতে সক...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>কয়েক বছর আগে আমার মাথায় আঘাত লেগেছিল এবং আমা...</td>\n",
              "      <td>আপনি বলেননি কি বা কত ওষুধ আপনি চেষ্টা করেছেন।...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5486</th>\n",
              "      <td>হ্যাঁ এটা সত্যিই</td>\n",
              "      <td>এটি একটি অবিচলিত গতিতে অর্জন করা হচ্ছে... এটি ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5487</th>\n",
              "      <td>আমি কাজ শেষে আজ রেজিস্ট্রেশন সেন্টারে গিয়েছিল...</td>\n",
              "      <td>এটাই সমস্যা। তুমি সেখানে কি করছ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5488</th>\n",
              "      <td>আমি কিছু বন্ধুদের সাথে ভলিবল খেলি। কাজের পরে আ...</td>\n",
              "      <td>চমৎকার আহ! তোমার জন্য ভালো. সম্ভবত একটি রান জন...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5489</th>\n",
              "      <td>আমি খুব রাগান্বিত হয়েছিলাম যখন আমার মা..যিনি ...</td>\n",
              "      <td>কি দারুন. তোর মাকে নিয়ে তোর খালা কি রেগে আছে?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5490</th>\n",
              "      <td>তিনি তাদের পিছন পিছন মানুষের সম্পর্কে খারাপ কথ...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5491 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b8ad8f3-eb9a-42ec-9af9-6df6074c3396')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1b8ad8f3-eb9a-42ec-9af9-6df6074c3396 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1b8ad8f3-eb9a-42ec-9af9-6df6074c3396');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ef2b8975-a04b-4162-91fd-3676ea620f10\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ef2b8975-a04b-4162-91fd-3676ea620f10')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ef2b8975-a04b-4162-91fd-3676ea620f10 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8A1fnh7uxS83"
      },
      "outputs": [],
      "source": [
        "# questions=[]\n",
        "# answers=[]\n",
        "\n",
        "# for i in df.Question:\n",
        "#   questions.append(i)\n",
        "\n",
        "# for i in df.Answer:\n",
        "#   answers.append(i)\n",
        "\n",
        "questions_eva=[]\n",
        "answers_eva=[]\n",
        "\n",
        "for i in df.Question:\n",
        "  questions_eva.append(i)\n",
        "\n",
        "for i in df.Answer:\n",
        "  answers_eva.append(i)\n",
        "\n",
        "\n",
        "# Remove rows with nan values in both 'Question' and 'Answer' columns\n",
        "df_cleaned = df.dropna(subset=['Question', 'Answer'])\n",
        "\n",
        "# Get the cleaned questions and answers\n",
        "questions = df_cleaned['Question'].tolist()\n",
        "answers = df_cleaned['Answer'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Za9sV6IbxwvH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad9d943a-16c8-4e5a-ba8e-e14359715936"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample question: এখন আমার রাগ এবং বিশ্বাসের সমস্যা আছে। আমি কিভাবে এটি চিকিত্সা করতে পারি এবং নিজেকে ঠিক করতে পারি?\n",
            "Sample answer:  আমি ধরে নেব যে কোন কারণেই হোক, আপনি হয় এই বিষয়ে কাউন্সেলিং নিতে চান না বা করতে পারছেন না। যাইহোক, আমি আপনাকে এটি করার জন্য অত্যন্ত অনুরোধ করছি কারণ দীর্ঘমেয়াদী শৈশব অপব্যবহার একজন প্রাপ্তবয়স্ক হিসাবে আপনার জীবনের জন্য নেতিবাচক পরিণতি ডেকে আনে, যেমনটি আপনি ইতিমধ্যেই সচেতন বলে মনে হচ্ছে৷ আপনি যৌন নিপীড়ন সঙ্গে যে চুক্তি বলতে পারেন. কিছু/বেশিরভাগ স্থানীয় এলাকায় বিনামূল্যে কাউন্সেলিং পরিষেবাও অফার করে। এটি দেখতে শুরু করার জন্য একটি ভাল জায়গা হবে, বিশেষ করে যদি কাউন্সেলিং খরচ একটি সমস্যা হয়।  জানা গুরুত্বপূর্ণ বিষয় হল যা ঘটেছে তা আপনার দোষ ছিল না এবং আপনি একটি সুখী জীবনযাপনের যোগ্য অতীত. এই জাতীয় কিছুর পরে রাগ এবং বিশ্বাসের সমস্যা থাকা আপনার সাথে যা ঘটেছে তার একটি সম্পূর্ণ স্বাভাবিক প্রতিক্রিয়া। রাগান্বিত? হ্যাঁ! তোমার ভাই যা করেছে তার জন্য, তোমাকে রক্ষা না করার জন্য তোমার বাবা-মায়ের কাছে। বিশ্বাস করতে সমস্যা হচ্ছে? অবশ্যই! যে লোকেরা আপনাকে ভালবাসতে এবং রক্ষা করার কথা ছিল তারাই বরং আপনাকে আঘাত করেছে। দুটি বই যা আপনাকে সাহায্য করতে পারে তা হল Co-dependent No More and Boundaries: Where You End and I Begin৷ \n"
          ]
        }
      ],
      "source": [
        "print('Sample question: {}'.format(questions[17]))\n",
        "print('Sample answer: {}'.format(answers[17]))\n",
        "X = questions_eva\n",
        "Y = answers_eva"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        ""
      ],
      "metadata": {
        "id": "-2hDcyIJhwvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gj6h05UBGze7"
      },
      "outputs": [],
      "source": [
        "pip install --upgrade pip\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8FJqzSHG0P7"
      },
      "source": [
        "# Transformer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)\n",
        "print(py)"
      ],
      "metadata": {
        "id": "I7wGO6e4bqpt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26f96d53-38d4-4627-9193-8e3ca10d9edf"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QuLnpt1-kFd"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-text\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(sys.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THLU0D9xg7bX",
        "outputId": "4fbfa9d7-eccb-4bae-9f51-d96cfc24251d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_datasets"
      ],
      "metadata": {
        "id": "dCkd9NzrWgnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TXLGgHLx8Fa"
      },
      "outputs": [],
      "source": [
        "import tensorflow_text as text\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
        "#     questions + answers, target_vocab_size=2**13)\n",
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "    questions + answers, target_vocab_size=2**13)\n",
        "# Define start and end token to indicate the start and end of a sentence\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
        "\n",
        "# Vocabulary size plus start and end token\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggPVFO4uyE1q"
      },
      "outputs": [],
      "source": [
        "print('Tokenized sample question: {}'.format(tokenizer.encode(questions[20])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZ7T0PQayH2p"
      },
      "outputs": [],
      "source": [
        "# Tokenize, filter and pad sentences\n",
        "def tokenize_and_filter(inputs, outputs):\n",
        "  tokenized_inputs, tokenized_outputs = [], []\n",
        "\n",
        "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
        "    # tokenize sentence\n",
        "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
        "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
        "    # check tokenized sentence max length\n",
        "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
        "      tokenized_inputs.append(sentence1)\n",
        "      tokenized_outputs.append(sentence2)\n",
        "\n",
        "  # pad tokenized sentences\n",
        "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
        "\n",
        "  return tokenized_inputs, tokenized_outputs\n",
        "\n",
        "\n",
        "questions, answers = tokenize_and_filter(questions, answers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtmMNH3tyMu3"
      },
      "outputs": [],
      "source": [
        "print('Vocab size: {}'.format(VOCAB_SIZE))\n",
        "print('Number of samples: {}'.format(len(questions)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBjtl7MDyQie"
      },
      "outputs": [],
      "source": [
        "# decoder inputs use the previous target as input\n",
        "# remove START_TOKEN from targets\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': questions,\n",
        "        'dec_inputs': answers[:, :-1]\n",
        "    },\n",
        "    {\n",
        "        'outputs': answers[:, 1:]\n",
        "    },\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYU39b09yVAW"
      },
      "outputs": [],
      "source": [
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHCo9oguyY6J"
      },
      "outputs": [],
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  \"\"\"Calculate the attention weights. \"\"\"\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "  # scale matmul_qk\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "  # add the mask to zero out padding tokens\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k)\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "  output = tf.matmul(attention_weights, value)\n",
        "\n",
        "  return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INq5tRU8yd4p"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "        'value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    # linear layers\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    # split heads\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    # scaled dot-product attention\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    # concatenation of heads\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "    # final linear layer\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqhGKN2JyjCx"
      },
      "outputs": [],
      "source": [
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, sequence length)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1_1lg9YymuK"
      },
      "outputs": [],
      "source": [
        "print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8Syf0Tsyoxk"
      },
      "outputs": [],
      "source": [
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x)\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9j3GYtyyrmf"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(create_look_ahead_mask(tf.constant([[1, 2, 0, 4, 5]])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xO2EaIW8yxvw"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "    # apply sin to even index in the array\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    # apply cos to odd index in the array\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uPTx2OYy2v1"
      },
      "outputs": [],
      "source": [
        "sample_pos_encoding = PositionalEncoding(50, 512)\n",
        "\n",
        "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
        "plt.xlabel('Depth')\n",
        "plt.xlim((0, 512))\n",
        "plt.ylabel('Position')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tr4Vuyjy4_N"
      },
      "outputs": [],
      "source": [
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3djJmKJy-Yt"
      },
      "outputs": [],
      "source": [
        "sample_encoder_layer = encoder_layer(\n",
        "    units=512,\n",
        "    d_model=128,\n",
        "    num_heads=4,\n",
        "    dropout=0.3,\n",
        "    name=\"sample_encoder_layer\")\n",
        "tf.keras.utils.plot_model(\n",
        "    sample_encoder_layer, to_file='encoder_layer.png', show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LeIcZhLSzA5u"
      },
      "outputs": [],
      "source": [
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name=\"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fK6PHDAIzJ3m"
      },
      "outputs": [],
      "source": [
        "\n",
        "sample_encoder = encoder(\n",
        "    vocab_size=2238,\n",
        "    num_layers=2,\n",
        "    units=512,\n",
        "    d_model=128,\n",
        "    num_heads=4,\n",
        "    dropout=0.3,\n",
        "    name=\"sample_encoder\")\n",
        "\n",
        "tf.keras.utils.plot_model(\n",
        "   sample_encoder, to_file='encoder.png', show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-uZHG5xzM3N"
      },
      "outputs": [],
      "source": [
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': look_ahead_mask\n",
        "      })\n",
        "  attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1,\n",
        "          'key': enc_outputs,\n",
        "          'value': enc_outputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXSH8aHZzTZG"
      },
      "outputs": [],
      "source": [
        "sample_decoder_layer = decoder_layer(\n",
        "    units=512,\n",
        "    d_model=128,\n",
        "    num_heads=4,\n",
        "    dropout=0.3,\n",
        "    name=\"sample_decoder_layer\")\n",
        "\n",
        "tf.keras.utils.plot_model(\n",
        "    sample_decoder_layer, to_file='decoder_layer.png', show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIIvmTKRzW4q"
      },
      "outputs": [],
      "source": [
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name='decoder'):\n",
        "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name='decoder_layer_{}'.format(i),\n",
        "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPRC02Hmzbux"
      },
      "outputs": [],
      "source": [
        "sample_decoder = decoder(\n",
        "    vocab_size=2238,\n",
        "    num_layers=2,\n",
        "    units=512,\n",
        "    d_model=128,\n",
        "    num_heads=4,\n",
        "    dropout=0.3,\n",
        "    name=\"sample_decoder\")\n",
        "\n",
        "tf.keras.utils.plot_model(\n",
        "    sample_decoder, to_file='decoder.png', show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AbS9459ze6w"
      },
      "outputs": [],
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(inputs)\n",
        "  # mask the future tokens for decoder inputs at the 1st attention block\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask,\n",
        "      output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "  # mask the encoder outputs for the 2nd attention block\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(inputs)\n",
        "\n",
        "  enc_outputs = encoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  dec_outputs = decoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtA7LP07ztXn"
      },
      "outputs": [],
      "source": [
        "sample_transformer = transformer(\n",
        "    vocab_size=2238,\n",
        "    num_layers=4,\n",
        "    units=512,\n",
        "    d_model=128,\n",
        "    num_heads=4,\n",
        "    dropout=0.3,\n",
        "    name=\"sample_transformer\")\n",
        "\n",
        "tf.keras.utils.plot_model(\n",
        "    sample_transformer, to_file='transformer.png', show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c276EOFq2Mg9"
      },
      "outputs": [],
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "\n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "\n",
        "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KOPBKH22SIW"
      },
      "outputs": [],
      "source": [
        "\n",
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fiAT9or2WBE"
      },
      "outputs": [],
      "source": [
        "sample_learning_rate = CustomSchedule(d_model=128)\n",
        "\n",
        "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEG-OU4F2Y2L"
      },
      "outputs": [],
      "source": [
        "\n",
        "# clear backend\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "# initialize and compile model within strategy scope\n",
        "with strategy.scope():\n",
        "  model = transformer(\n",
        "      vocab_size=VOCAB_SIZE,\n",
        "      num_layers=NUM_LAYERS,\n",
        "      units=UNITS,\n",
        "      d_model=D_MODEL,\n",
        "      num_heads=NUM_HEADS,\n",
        "      dropout=DROPOUT)\n",
        "\n",
        "  model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwUyp6HP2ex-"
      },
      "outputs": [],
      "source": [
        "#model fit and train\n",
        "history=model.fit(dataset, epochs=EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RiANI5VC-1ra"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model, to_file='model.png', show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unp54i7a2jFi"
      },
      "outputs": [],
      "source": [
        "def evaluate(sentence):\n",
        "\n",
        "  sentence = tf.expand_dims(\n",
        "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
        "\n",
        "  output = tf.expand_dims(START_TOKEN, 0)\n",
        "\n",
        "  for i in range(MAX_LENGTH):\n",
        "    predictions = model(inputs=[sentence, output], training=False)\n",
        "\n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[:, -1:, :]\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
        "      break\n",
        "\n",
        "    # concatenated the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output, axis=0)\n",
        "\n",
        "\n",
        "def predict(sentence):\n",
        "  prediction = evaluate(sentence)\n",
        "\n",
        "  predicted_sentence = tokenizer.decode(\n",
        "      [i for i in prediction if i < tokenizer.vocab_size])\n",
        "\n",
        "  print('Input: {}'.format(sentence))\n",
        "  print('Output: {}'.format(predicted_sentence))\n",
        "\n",
        "  return predicted_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0NXyHvc24Ly"
      },
      "outputs": [],
      "source": [
        "output = predict('এখন আমার রাগ এবং বিশ্বাসের সমস্যা আছে। আমি কিভাবে এটি চিকিত্সা করতে পারি এবং নিজেকে ঠিক করতে পারি?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHUkZSKm24_j"
      },
      "outputs": [],
      "source": [
        "sentence=\"এখন আমার রাগ এবং বিশ্বাসের সমস্যা আছে। আমি কিভাবে এটি চিকিত্সা করতে পারি এবং নিজেকে ঠিক করতে পারি?\"\n",
        "for _ in range(10):\n",
        "  sentence = predict(sentence)\n",
        "  print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IjNuZkbzZOq"
      },
      "outputs": [],
      "source": [
        "print('Sample question: {}'.format(questions[17]))\n",
        "print('Sample answer: {}'.format(answers[17]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8ZpquHNzX16"
      },
      "outputs": [],
      "source": [
        "print('Sample question: {}'.format(questions[17]))\n",
        "print('Sample answer: {}'.format(answers[17]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ibgRdA63ZV3"
      },
      "outputs": [],
      "source": [
        "import tqdm\n",
        "from nltk.translate.bleu_score import sentence_bleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KA2fxweLCB8P"
      },
      "outputs": [],
      "source": [
        "X = questions_eva\n",
        "Y = answers_eva"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBmmlGePCEA1"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
        "len (Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEN7btR8CIFC"
      },
      "outputs": [],
      "source": [
        "\n",
        "# fr_preds = []\n",
        "# for sentence in tqdm.tqdm(X_test):\n",
        "#     fr_pred = predict(sentence)\n",
        "#     fr_preds.append(fr_pred)\n",
        "fr_preds = []\n",
        "for sentence in tqdm.tqdm(X_test[10]):\n",
        "    fr_pred = predict(sentence)\n",
        "    fr_preds.append(fr_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d10HHUgQCKNl"
      },
      "outputs": [],
      "source": [
        "references = Y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_7DDUy-GJgT"
      },
      "outputs": [],
      "source": [
        "bleu_score_1 = []\n",
        "bleu_score_2 = []\n",
        "bleu_score_3 = []\n",
        "bleu_score_4 = []\n",
        "\n",
        "for i in tqdm.tqdm(range(len(fr_preds))):\n",
        "    pred = fr_preds[i].replace(\"<EOS>\", \"\").replace(\"<PAD>\", \"\").replace(\"<UNK>\", \"\").replace(\"<GO>\", \"\").rstrip()\n",
        "    reference = references[i].lower().replace(\"<EOS>\", \"\").replace(\"<PAD>\", \"\").replace(\"<UNK>\", \"\").replace(\"<GO>\", \"\").rstrip()\n",
        "\n",
        "    score_1 = sentence_bleu([reference.split()], pred.split(), weights=(1, 0, 0, 0))\n",
        "    score_2 = sentence_bleu([reference.split()], pred.split(), weights=(0, 1, 0, 0))\n",
        "    score_3 = sentence_bleu([reference.split()], pred.split(), weights=(0, 0, 1, 0))\n",
        "    score_4 = sentence_bleu([reference.split()], pred.split(), weights=(0, 0, 0, 1))\n",
        "\n",
        "\n",
        "#     score_1 = sentence_bleu([reference.split()], pred.split(), weights=(1, 0, 0, 0))\n",
        "#     score_2 = sentence_bleu([reference.split()], pred.split(), weights=(0.5, 0.5, 0, 0))\n",
        "#     score_3 = sentence_bleu([reference.split()], pred.split(), weights=(0.34, 0.33, 0.33, 0.))\n",
        "#     score_4 = sentence_bleu([reference.split()], pred.split(), weights=(0.25, 0.25, 0.25, 0.25))\n",
        "\n",
        "\n",
        "\n",
        "    bleu_score_1.append(score_1)\n",
        "    bleu_score_2.append(score_2)\n",
        "    bleu_score_3.append(score_3)\n",
        "    bleu_score_4.append(score_4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcKbIeO2GRI5"
      },
      "outputs": [],
      "source": [
        "print(\"The BLEU score individual 1-gram on our corpus is about {}\".format(sum(bleu_score_1) / len(bleu_score_1)))\n",
        "print(\"The BLEU score individual 2-gram on our corpus is about {}\".format(sum(bleu_score_2) / len(bleu_score_2)))\n",
        "print(\"The BLEU score individual 3-gram on our corpus is about {}\".format(sum(bleu_score_3) / len(bleu_score_3)))\n",
        "print(\"The BLEU score individual 4-gram on our corpus is about {}\".format(sum(bleu_score_4) / len(bleu_score_4)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksQ_g0tWGUdw"
      },
      "outputs": [],
      "source": [
        "bleu_score_1 = []\n",
        "bleu_score_2 = []\n",
        "bleu_score_3 = []\n",
        "bleu_score_4 = []\n",
        "\n",
        "for i in tqdm.tqdm(range(len(fr_preds))):\n",
        "    pred = fr_preds[i].replace(\"<EOS>\", \"\").replace(\"<PAD>\", \"\").replace(\"<UNK>\", \"\").replace(\"<GO>\", \"\").rstrip()\n",
        "    reference = references[i].lower()\n",
        "#     score_1 = sentence_bleu([reference.split()], pred.split(), weights=(1, 0, 0, 0))\n",
        "#     score_2 = sentence_bleu([reference.split()], pred.split(), weights=(0, 1, 0, 0))\n",
        "#     score_3 = sentence_bleu([reference.split()], pred.split(), weights=(0, 0, 1, 0))\n",
        "#     score_4 = sentence_bleu([reference.split()], pred.split(), weights=(0, 0, 0, 1))\n",
        "\n",
        "\n",
        "    score_1 = sentence_bleu([reference.split()], pred.split(), weights=(1, 0, 0, 0))\n",
        "    score_2 = sentence_bleu([reference.split()], pred.split(), weights=(0.5, 0.5, 0, 0))\n",
        "    score_3 = sentence_bleu([reference.split()], pred.split(), weights=(0.34, 0.33, 0.33, 0.))\n",
        "    score_4 = sentence_bleu([reference.split()], pred.split(), weights=(0.25, 0.25, 0.25, 0.25))\n",
        "\n",
        "\n",
        "\n",
        "    bleu_score_1.append(score_1)\n",
        "    bleu_score_2.append(score_2)\n",
        "    bleu_score_3.append(score_3)\n",
        "    bleu_score_4.append(score_4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrJutvSzGh8Y"
      },
      "outputs": [],
      "source": [
        "print(\"The BLEU score cumulative 1-gram on our corpus is about {}\".format(sum(bleu_score_1) / len(bleu_score_1)))\n",
        "print(\"The BLEU score cumulative 2-gram on our corpus is about {}\".format(sum(bleu_score_2) / len(bleu_score_2)))\n",
        "print(\"The BLEU score cumulative 3-gram on our corpus is about {}\".format(sum(bleu_score_3) / len(bleu_score_3)))\n",
        "print(\"The BLEU score cumulative 4-gram on our corpus is about {}\".format(sum(bleu_score_4) / len(bleu_score_4)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vHMhdkgGlTp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a4EjivBG5OW"
      },
      "source": [
        "# Seq2Seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "4uHi9AcCal9p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40d4f584-9f93-44ba-bde5-28cd0ac83a1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from keras.layers import Input, Embedding, LSTM, TimeDistributed, Dense, Bidirectional\n",
        "from keras.models import Model, load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Etb0FZlqZgYU"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    '''Clean text by removing unnecessary characters and altering the format of words.'''\n",
        "    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
        "    text = \" \".join(text.split())\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "K7s79B6UZln5"
      },
      "outputs": [],
      "source": [
        "# Clean the data\n",
        "clean_questions = []\n",
        "for question in df.Question:\n",
        "    clean_questions.append(clean_text(str(question)))\n",
        "clean_answers = []\n",
        "for answer in df.Answer:\n",
        "    clean_answers.append(clean_text(str(answer)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "3bOo2LojZsJH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b781bf49-73c2-4aef-83e2-7fc2ba376614"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47.0\n",
            "73.0\n",
            "110.0\n",
            "178.0\n"
          ]
        }
      ],
      "source": [
        "# Find the length of sentences (not using nltk due to processing speed)\n",
        "lengths = []\n",
        "# lengths.append([len(nltk.word_tokenize(sent)) for sent in clean_questions]) #nltk approach\n",
        "for question in clean_questions:\n",
        "    lengths.append(len(question.split()))\n",
        "for answer in clean_answers:\n",
        "    lengths.append(len(answer.split()))\n",
        "# Create a dataframe so that the values can be inspected\n",
        "lengths = pd.DataFrame(lengths, columns=['counts'])\n",
        "print(np.percentile(lengths, 80))\n",
        "print(np.percentile(lengths, 85))\n",
        "print(np.percentile(lengths, 90))\n",
        "print(np.percentile(lengths, 95))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "vWne59GZZvbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae8b9a27-5140-44cf-8cf2-93c7900b5b6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2106\n",
            "2106\n"
          ]
        }
      ],
      "source": [
        "# Remove questions and answers that are shorter than 1 word and longer than 20 words.\n",
        "min_line_length = 0\n",
        "max_line_length = 15\n",
        "\n",
        "# Filter out the questions that are too short/long\n",
        "short_questions_temp = []\n",
        "short_answers_temp = []\n",
        "\n",
        "for i, question in enumerate(clean_questions):\n",
        "    if len(question.split()) >= min_line_length and len(question.split()) <= max_line_length:\n",
        "        short_questions_temp.append(question)\n",
        "        short_answers_temp.append(clean_answers[i])\n",
        "\n",
        "# Filter out the answers that are too short/long\n",
        "short_questions = []\n",
        "short_answers = []\n",
        "\n",
        "for i, answer in enumerate(short_answers_temp):\n",
        "    if len(answer.split()) >= min_line_length and len(answer.split()) <= max_line_length:\n",
        "        short_answers.append(answer)\n",
        "        short_questions.append(short_questions_temp[i])\n",
        "\n",
        "print(len(short_questions))\n",
        "print(len(short_answers))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "T9VbQlKZZ4w8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d03055ea-ddb5-4572-f980-62f47c651987"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "এটি আসলে একটি নির্দিষ্ট সংস্করণ এটি পুরানো গেম থেকে সবকিছু আছে\n",
            "ওহ বাহ আমি সেগুলি সব খেলিনি তবে আমি প্রথমটি করেছি।\n",
            "\n",
            "আমি নতুন সুপার স্ম্যাশ ব্রোস গেমের জন্য উত্তেজিত যেটি শীঘ্রই আসছে\n",
            "আমি এর সাথে পরিচিত নই আমাকে আরও বলুন।\n",
            "\n",
            "এটি মারিও জেল্ডা এবং পোকেমন চরিত্রের মতো নিন্টেন্ডো চরিত্রগুলির সাথে একটি লড়াইয়ের খেলা\n",
            "এটা মজার শোনাচ্ছে কোন গেম প্ল্যাটফর্ম\n",
            "\n"
          ]
        }
      ],
      "source": [
        "r = np.random.randint(1,len(short_questions))\n",
        "\n",
        "for i in range(r, r+3):\n",
        "    print(short_questions[i])\n",
        "    print(short_answers[i])\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "USAIL2VNaXnh"
      },
      "outputs": [],
      "source": [
        "#choosing number of samples\n",
        "num_samples = 15000  # Number of samples to train on.\n",
        "short_questions = short_questions[:num_samples]\n",
        "short_answers = short_answers[:num_samples]\n",
        "#tokenizing the qns and answers\n",
        "short_questions_tok = [nltk.word_tokenize(sent) for sent in short_questions]\n",
        "short_answers_tok = [nltk.word_tokenize(sent) for sent in short_answers]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "FGgN-MRvacqS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e34d564c-5f12-44eb-e207-c0046acd9be1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training size 1685\n",
            "validation size 421\n"
          ]
        }
      ],
      "source": [
        "#train-validation split\n",
        "data_size = len(short_questions_tok)\n",
        "\n",
        "# We will use the first 0-80th %-tile (80%) of data for the training\n",
        "training_input  = short_questions_tok[:round(data_size*(80/100))]\n",
        "training_input  = [tr_input[::-1] for tr_input in training_input] #reverseing input seq for better performance\n",
        "training_output = short_answers_tok[:round(data_size*(80/100))]\n",
        "\n",
        "# We will use the remaining for validation\n",
        "validation_input = short_questions_tok[round(data_size*(80/100)):]\n",
        "validation_input  = [val_input[::-1] for val_input in validation_input] #reverseing input seq for better performance\n",
        "validation_output = short_answers_tok[round(data_size*(80/100)):]\n",
        "\n",
        "print('training size', len(training_input))\n",
        "print('validation size', len(validation_input))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "OHhNjOq0a0-x"
      },
      "outputs": [],
      "source": [
        "# Create a dictionary for the frequency of the vocabulary\n",
        "# Create\n",
        "vocab = {}\n",
        "for question in short_questions_tok:\n",
        "    for word in question:\n",
        "        if word not in vocab:\n",
        "            vocab[word] = 1\n",
        "        else:\n",
        "            vocab[word] += 1\n",
        "\n",
        "for answer in short_answers_tok:\n",
        "    for word in answer:\n",
        "        if word not in vocab:\n",
        "            vocab[word] = 1\n",
        "        else:\n",
        "            vocab[word] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "0GY_XRGva8EM"
      },
      "outputs": [],
      "source": [
        "threshold = 2\n",
        "count = 0\n",
        "for k,v in vocab.items():\n",
        "    if v >= threshold:\n",
        "        count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "LDFCAVp0a-UO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6e8787e-7f37-4ec7-c594-aca6f3e2f923"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of total vocab: 5163\n",
            "Size of vocab we will use: 2366\n"
          ]
        }
      ],
      "source": [
        "print(\"Size of total vocab:\", len(vocab))\n",
        "print(\"Size of vocab we will use:\", count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "AfETy7e4bW8L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f95a8572-048f-4acb-af9a-d4acfda8d214"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of vocab used: 2368\n"
          ]
        }
      ],
      "source": [
        "#we will create dictionaries to provide a unique integer for each word.\n",
        "WORD_CODE_START = 1\n",
        "WORD_CODE_PADDING = 0\n",
        "\n",
        "\n",
        "word_num  = 2 #number 1 is left for WORD_CODE_START for model decoder later\n",
        "encoding = {}\n",
        "decoding = {1: 'START'}\n",
        "for word, count in vocab.items():\n",
        "    if count >= threshold: #get vocabularies that appear above threshold count\n",
        "        encoding[word] = word_num\n",
        "        decoding[word_num ] = word\n",
        "        word_num += 1\n",
        "\n",
        "print(\"No. of vocab used:\", word_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "k87Y6uqHbant"
      },
      "outputs": [],
      "source": [
        "#include unknown token for words not in dictionary\n",
        "decoding[len(encoding)+2] = '<UNK>'\n",
        "encoding['<UNK>'] = len(encoding)+2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "1bhaNiJMbeEy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af428a6b-57a1-4bcf-b82e-4b5452d05955"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2369"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "dict_size = word_num+1\n",
        "dict_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "49jATTaEbpMa"
      },
      "outputs": [],
      "source": [
        "def transform(encoding, data, vector_size=20):\n",
        "\n",
        "    transformed_data = np.zeros(shape=(len(data), vector_size))\n",
        "    for i in range(len(data)):\n",
        "        for j in range(min(len(data[i]), vector_size)):\n",
        "            try:\n",
        "                transformed_data[i][j] = encoding[data[i][j]]\n",
        "            except:\n",
        "                transformed_data[i][j] = encoding['<UNK>']\n",
        "    return transformed_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "mqXg2Pa_bsMX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "214b4e6e-c635-4c65-c656-dee2c21cf55a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoded_training_input (1685, 15)\n",
            "encoded_training_output (1685, 5)\n"
          ]
        }
      ],
      "source": [
        "#encoding training set\n",
        "INPUT_LENGTH = 15\n",
        "OUTPUT_LENGTH = 5\n",
        "\n",
        "encoded_training_input = transform(\n",
        "    encoding, training_input, vector_size=INPUT_LENGTH)\n",
        "encoded_training_output = transform(\n",
        "    encoding, training_output, vector_size=OUTPUT_LENGTH)\n",
        "\n",
        "print('encoded_training_input', encoded_training_input.shape)\n",
        "print('encoded_training_output', encoded_training_output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "R1mpyyWWbuwq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dd0393d-b59c-4e25-88bd-9ff3e61e76ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoded_validation_input (421, 15)\n",
            "encoded_validation_output (421, 5)\n"
          ]
        }
      ],
      "source": [
        "#encoding validation set\n",
        "encoded_validation_input = transform(\n",
        "    encoding, validation_input, vector_size=INPUT_LENGTH)\n",
        "encoded_validation_output = transform(\n",
        "    encoding, validation_output, vector_size=OUTPUT_LENGTH)\n",
        "\n",
        "print('encoded_validation_input', encoded_validation_input.shape)\n",
        "print('encoded_validation_output', encoded_validation_output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "KSaD14WMcAlx"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "xidzMHOWcDRg"
      },
      "outputs": [],
      "source": [
        "INPUT_LENGTH = 15\n",
        "OUTPUT_LENGTH = 5\n",
        "\n",
        "encoder_input = Input(shape=(INPUT_LENGTH,))\n",
        "decoder_input = Input(shape=(OUTPUT_LENGTH,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "HiqUgUw8cIGU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2d23775-5b36-4673-efd0-7e81c424351b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder KerasTensor(type_spec=TensorSpec(shape=(None, 15, 512), dtype=tf.float32, name=None), name='lstm/transpose_2:0', description=\"created by layer 'lstm'\")\n",
            "encoder_last KerasTensor(type_spec=TensorSpec(shape=(None, 512), dtype=tf.float32, name=None), name='tf.__operators__.getitem/strided_slice:0', description=\"created by layer 'tf.__operators__.getitem'\")\n",
            "decoder KerasTensor(type_spec=TensorSpec(shape=(None, 5, 512), dtype=tf.float32, name=None), name='lstm_1/transpose_2:0', description=\"created by layer 'lstm_1'\")\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import SimpleRNN\n",
        "\n",
        "encoder = Embedding(dict_size, 128, input_length=INPUT_LENGTH, mask_zero=True)(encoder_input)\n",
        "encoder = LSTM(512, return_sequences=True, unroll=True)(encoder)\n",
        "encoder_last = encoder[:,-1,:]\n",
        "\n",
        "print('encoder', encoder)\n",
        "print('encoder_last', encoder_last)\n",
        "\n",
        "decoder = Embedding(dict_size, 128, input_length=OUTPUT_LENGTH, mask_zero=True)(decoder_input)\n",
        "decoder = LSTM(512, return_sequences=True, unroll=True)(decoder, initial_state=[encoder_last, encoder_last])\n",
        "\n",
        "print('decoder', decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "tlrSSiUpcK90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8df41462-be5f-4e9a-edc9-32b38bb94846"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attention KerasTensor(type_spec=TensorSpec(shape=(None, 5, 15), dtype=tf.float32, name=None), name='attention/Softmax:0', description=\"created by layer 'attention'\")\n",
            "context KerasTensor(type_spec=TensorSpec(shape=(None, 5, 512), dtype=tf.float32, name=None), name='dot_1/MatMul:0', description=\"created by layer 'dot_1'\")\n",
            "decoder_combined_context KerasTensor(type_spec=TensorSpec(shape=(None, 5, 1024), dtype=tf.float32, name=None), name='concatenate/concat:0', description=\"created by layer 'concatenate'\")\n",
            "output KerasTensor(type_spec=TensorSpec(shape=(None, 5, 2369), dtype=tf.float32, name=None), name='time_distributed_1/Reshape_1:0', description=\"created by layer 'time_distributed_1'\")\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import Activation, dot, concatenate\n",
        "\n",
        "# Equation (7) with 'dot' score from Section 3.1 in the paper.\n",
        "# Note that we reuse Softmax-activation layer instead of writing tensor calculation\n",
        "attention = dot([decoder, encoder], axes=[2, 2])\n",
        "attention = Activation('softmax', name='attention')(attention)\n",
        "print('attention', attention)\n",
        "\n",
        "context = dot([attention, encoder], axes=[2,1])\n",
        "print('context', context)\n",
        "\n",
        "decoder_combined_context = concatenate([context, decoder])\n",
        "print('decoder_combined_context', decoder_combined_context)\n",
        "\n",
        "# Has another weight + tanh layer as described in equation (5) of the paper\n",
        "output = TimeDistributed(Dense(512, activation=\"tanh\"))(decoder_combined_context)\n",
        "output = TimeDistributed(Dense(dict_size, activation=\"softmax\"))(output)\n",
        "print('output', output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "rJK1DtvgcO5-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b61cbbb-801e-45d0-dfb8-5869e49cfa31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 15)]                 0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, 15, 128)              303232    ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 5)]                  0         []                            \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 (None, 15, 512)              1312768   ['embedding[0][0]']           \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)     (None, 5, 128)               303232    ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (  (None, 512)                  0         ['lstm[0][0]']                \n",
            " SlicingOpLambda)                                                                                 \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               (None, 5, 512)               1312768   ['embedding_1[0][0]',         \n",
            "                                                                     'tf.__operators__.getitem[0][\n",
            "                                                                    0]',                          \n",
            "                                                                     'tf.__operators__.getitem[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " dot (Dot)                   (None, 5, 15)                0         ['lstm_1[0][0]',              \n",
            "                                                                     'lstm[0][0]']                \n",
            "                                                                                                  \n",
            " attention (Activation)      (None, 5, 15)                0         ['dot[0][0]']                 \n",
            "                                                                                                  \n",
            " dot_1 (Dot)                 (None, 5, 512)               0         ['attention[0][0]',           \n",
            "                                                                     'lstm[0][0]']                \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 5, 1024)              0         ['dot_1[0][0]',               \n",
            "                                                                     'lstm_1[0][0]']              \n",
            "                                                                                                  \n",
            " time_distributed (TimeDist  (None, 5, 512)               524800    ['concatenate[0][0]']         \n",
            " ributed)                                                                                         \n",
            "                                                                                                  \n",
            " time_distributed_1 (TimeDi  (None, 5, 2369)              1215297   ['time_distributed[0][0]']    \n",
            " stributed)                                                                                       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4972097 (18.97 MB)\n",
            "Trainable params: 4972097 (18.97 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Model(inputs=[encoder_input, decoder_input], outputs=[output])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['categorical_accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "foNFyU22cRTw"
      },
      "outputs": [],
      "source": [
        "training_encoder_input = encoded_training_input\n",
        "training_decoder_input = np.zeros_like(encoded_training_output)\n",
        "training_decoder_input[:, 1:] = encoded_training_output[:,:-1]\n",
        "training_decoder_input[:, 0] = WORD_CODE_START\n",
        "training_decoder_output =np.eye(dict_size)[encoded_training_output.astype('int')]\n",
        "\n",
        "validation_encoder_input = encoded_validation_input\n",
        "validation_decoder_input = np.zeros_like(encoded_validation_output)\n",
        "validation_decoder_input[:, 1:] = encoded_validation_output[:,:-1]\n",
        "validation_decoder_input[:, 0] = WORD_CODE_START\n",
        "validation_decoder_output = np.eye(dict_size)[encoded_validation_output.astype('int')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Tavelc1cVx8"
      },
      "outputs": [],
      "source": [
        "model.fit(x=[training_encoder_input, training_decoder_input], y=[training_decoder_output],\n",
        "          validation_data=([validation_encoder_input, validation_decoder_input], [validation_decoder_output]),\n",
        "          #validation_split=0.05,\n",
        "          batch_size=64, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRzFWVVscZio"
      },
      "outputs": [],
      "source": [
        "def prediction(raw_input):\n",
        "    clean_input = clean_text(raw_input)\n",
        "    input_tok = [nltk.word_tokenize(clean_input)]\n",
        "    input_tok = [input_tok[0][::-1]]  #reverseing input seq\n",
        "    encoder_input = transform(encoding, input_tok, 15)\n",
        "    decoder_input = np.zeros(shape=(len(encoder_input), OUTPUT_LENGTH))\n",
        "    decoder_input[:,0] = WORD_CODE_START\n",
        "    for i in range(1, OUTPUT_LENGTH):\n",
        "        output = model.predict([encoder_input, decoder_input]).argmax(axis=2)\n",
        "        decoder_input[:,i] = output[:,i]\n",
        "    return output\n",
        "\n",
        "def decode(decoding, vector):\n",
        "\n",
        "    text = ''\n",
        "    for i in vector:\n",
        "        if i == 0:\n",
        "            break\n",
        "        text += ' '\n",
        "        text += decoding[i]\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dt9Qt2Q_cizS"
      },
      "outputs": [],
      "source": [
        "for i in range(15):\n",
        "    seq_index = np.random.randint(1, len(short_questions))\n",
        "    output = prediction(short_questions[seq_index])\n",
        "    print ('Q:', short_questions[seq_index])\n",
        "    print ('A:', decode(decoding, output[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCrDqM1fcmuc"
      },
      "outputs": [],
      "source": [
        "import tqdm\n",
        "from nltk.translate.bleu_score import sentence_bleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_ZBKw7Xc4YN"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
        "len (Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_test)\n",
        "X_test=X_test[0:10]"
      ],
      "metadata": {
        "id": "VfuqzmYUP8GA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKJU2AJmc9lA"
      },
      "outputs": [],
      "source": [
        "fr_preds = []\n",
        "for sentence in tqdm.tqdm(X_test):\n",
        "    fr_pred = decode(decoding, prediction(sentence)[0])\n",
        "    fr_preds.append(fr_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lO98bA_7dAKK"
      },
      "outputs": [],
      "source": [
        "\n",
        "references = Y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hl6b8iP_dDBF"
      },
      "outputs": [],
      "source": [
        "bleu_score_1 = []\n",
        "bleu_score_2 = []\n",
        "bleu_score_3 = []\n",
        "bleu_score_4 = []\n",
        "\n",
        "for i in tqdm.tqdm(range(len(fr_preds))):\n",
        "\n",
        "    pred = fr_preds[i].replace(\"<EOS>\", \"\").replace(\"<PAD>\", \"\").replace(\"<UNK>\", \"\").replace(\"<GO>\", \"\").rstrip()\n",
        "    reference = references[i].lower().replace(\"<EOS>\", \"\").replace(\"<PAD>\", \"\").replace(\"<UNK>\", \"\").replace(\"<GO>\", \"\").rstrip()\n",
        "\n",
        "    score_1 = sentence_bleu([reference.split()], pred.split(), weights=(1, 0, 0, 0))\n",
        "    score_2 = sentence_bleu([reference.split()], pred.split(), weights=(0, 1, 0, 0))\n",
        "    score_3 = sentence_bleu([reference.split()], pred.split(), weights=(0, 0, 1, 0))\n",
        "    score_4 = sentence_bleu([reference.split()], pred.split(), weights=(0, 0, 0, 1))\n",
        "\n",
        "\n",
        "#     score_1 = sentence_bleu([reference.split()], pred.split(), weights=(1, 0, 0, 0))\n",
        "#     score_2 = sentence_bleu([reference.split()], pred.split(), weights=(0.5, 0.5, 0, 0))\n",
        "#     score_3 = sentence_bleu([reference.split()], pred.split(), weights=(0.34, 0.33, 0.33, 0.))\n",
        "#     score_4 = sentence_bleu([reference.split()], pred.split(), weights=(0.25, 0.25, 0.25, 0.25))\n",
        "\n",
        "\n",
        "\n",
        "    bleu_score_1.append(score_1)\n",
        "    bleu_score_2.append(score_2)\n",
        "    bleu_score_3.append(score_3)\n",
        "    bleu_score_4.append(score_4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAfJK_5qdHPz"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"The BLEU score individual 1-gram on our corpus is about {}\".format(sum(bleu_score_1) / len(bleu_score_1)))\n",
        "print(\"The BLEU score individual 2-gram on our corpus is about {}\".format(sum(bleu_score_2) / len(bleu_score_2)))\n",
        "print(\"The BLEU score individual 3-gram on our corpus is about {}\".format(sum(bleu_score_3) / len(bleu_score_3)))\n",
        "print(\"The BLEU score individual 4-gram on our corpus is about {}\".format(sum(bleu_score_4) / len(bleu_score_4)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRV_0D5pdK-M"
      },
      "outputs": [],
      "source": [
        "bleu_score_1 = []\n",
        "bleu_score_2 = []\n",
        "bleu_score_3 = []\n",
        "bleu_score_4 = []\n",
        "\n",
        "for i in tqdm.tqdm(range(len(fr_preds))):\n",
        "\n",
        "    pred = fr_preds[i].replace(\"<EOS>\", \"\").replace(\"<PAD>\", \"\").replace(\"<UNK>\", \"\").replace(\"<GO>\", \"\").rstrip()\n",
        "    reference = references[i].lower()\n",
        "#     计算BLEU分数\n",
        "#     score_1 = sentence_bleu([reference.split()], pred.split(), weights=(1, 0, 0, 0))\n",
        "#     score_2 = sentence_bleu([reference.split()], pred.split(), weights=(0, 1, 0, 0))\n",
        "#     score_3 = sentence_bleu([reference.split()], pred.split(), weights=(0, 0, 1, 0))\n",
        "#     score_4 = sentence_bleu([reference.split()], pred.split(), weights=(0, 0, 0, 1))\n",
        "\n",
        "\n",
        "    score_1 = sentence_bleu([reference.split()], pred.split(), weights=(1, 0, 0, 0))\n",
        "    score_2 = sentence_bleu([reference.split()], pred.split(), weights=(0.5, 0.5, 0, 0))\n",
        "    score_3 = sentence_bleu([reference.split()], pred.split(), weights=(0.34, 0.33, 0.33, 0.))\n",
        "    score_4 = sentence_bleu([reference.split()], pred.split(), weights=(0.25, 0.25, 0.25, 0.25))\n",
        "\n",
        "\n",
        "\n",
        "    bleu_score_1.append(score_1)\n",
        "    bleu_score_2.append(score_2)\n",
        "    bleu_score_3.append(score_3)\n",
        "    bleu_score_4.append(score_4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtgDSSd9dPgC"
      },
      "outputs": [],
      "source": [
        "print(\"The BLEU score cumulative 1-gram on our corpus is about {}\".format(sum(bleu_score_1) / len(bleu_score_1)))\n",
        "print(\"The BLEU score cumulative 2-gram on our corpus is about {}\".format(sum(bleu_score_2) / len(bleu_score_2)))\n",
        "print(\"The BLEU score cumulative 3-gram on our corpus is about {}\".format(sum(bleu_score_3) / len(bleu_score_3)))\n",
        "print(\"The BLEU score cumulative 4-gram on our corpus is about {}\".format(sum(bleu_score_4) / len(bleu_score_4)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJJydXJcdSsJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "4a4EjivBG5OW"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}